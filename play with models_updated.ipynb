{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imblearn\n",
      "  Downloading imblearn-0.0-py2.py3-none-any.whl (1.9 kB)\n",
      "Collecting imbalanced-learn\n",
      "  Downloading imbalanced_learn-0.8.0-py3-none-any.whl (206 kB)\n",
      "\u001b[K     |████████████████████████████████| 206 kB 2.4 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: joblib>=0.11 in ./opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (0.16.0)\n",
      "Collecting scikit-learn>=0.24\n",
      "  Downloading scikit_learn-0.24.2-cp38-cp38-macosx_10_13_x86_64.whl (7.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 7.2 MB 1.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in ./opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.18.5)\n",
      "Requirement already satisfied: scipy>=0.19.1 in ./opt/anaconda3/lib/python3.8/site-packages (from imbalanced-learn->imblearn) (1.5.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in ./opt/anaconda3/lib/python3.8/site-packages (from scikit-learn>=0.24->imbalanced-learn->imblearn) (2.1.0)\n",
      "Installing collected packages: scikit-learn, imbalanced-learn, imblearn\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.23.1\n",
      "    Uninstalling scikit-learn-0.23.1:\n",
      "      Successfully uninstalled scikit-learn-0.23.1\n",
      "Successfully installed imbalanced-learn-0.8.0 imblearn-0.0 scikit-learn-0.24.2\n"
     ]
    }
   ],
   "source": [
    "!pip3 install imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_PEP</th>\n",
       "      <th>PEP01</th>\n",
       "      <th>PEP02</th>\n",
       "      <th>PEP03_avto</th>\n",
       "      <th>PEP03_home</th>\n",
       "      <th>PEP03_land</th>\n",
       "      <th>PEP04_adress</th>\n",
       "      <th>PEP04_region</th>\n",
       "      <th>PEP05</th>\n",
       "      <th>...</th>\n",
       "      <th>PEP22</th>\n",
       "      <th>PEP23</th>\n",
       "      <th>PEP24</th>\n",
       "      <th>PEP25</th>\n",
       "      <th>PEP26</th>\n",
       "      <th>PEP27</th>\n",
       "      <th>PEP07</th>\n",
       "      <th>score</th>\n",
       "      <th>final_score</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>9944</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>3.44</td>\n",
       "      <td>mid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>6179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>702</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>9970</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.31</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6126</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.16</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>9496</td>\n",
       "      <td>26254</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.15</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>9497</td>\n",
       "      <td>26078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.15</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>9498</td>\n",
       "      <td>47966</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.48</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9499</th>\n",
       "      <td>9499</td>\n",
       "      <td>33880</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>1.48</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9500</th>\n",
       "      <td>9500</td>\n",
       "      <td>32833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.49</td>\n",
       "      <td>low</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9501 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0  id_PEP  PEP01  PEP02  PEP03_avto  PEP03_home  PEP03_land  \\\n",
       "0              0    9944      1      0           1           0           1   \n",
       "1              1    6179      1      0           0           0           0   \n",
       "2              2     702      1      0           0           0           0   \n",
       "3              3    9970      1      0           0           0           0   \n",
       "4              4    6126      1      0           0           0           0   \n",
       "...          ...     ...    ...    ...         ...         ...         ...   \n",
       "9496        9496   26254      0      0           0           0           0   \n",
       "9497        9497   26078      0      0           0           0           0   \n",
       "9498        9498   47966      0      0           0           0           0   \n",
       "9499        9499   33880      0      0           0           0           0   \n",
       "9500        9500   32833      0      0           0           0           0   \n",
       "\n",
       "      PEP04_adress  PEP04_region  PEP05  ...  PEP22  PEP23  PEP24  PEP25  \\\n",
       "0                1             0      0  ...      1      0      0      0   \n",
       "1                0             0      0  ...      0      0      0      0   \n",
       "2                0             0      0  ...      0      0      0      0   \n",
       "3                1             0      0  ...      0      0      0      0   \n",
       "4                0             0      0  ...      0      0      0      0   \n",
       "...            ...           ...    ...  ...    ...    ...    ...    ...   \n",
       "9496             0             0      0  ...      0      0      0      1   \n",
       "9497             0             0      0  ...      0      0      0      1   \n",
       "9498             0             0      0  ...      0      0      0      0   \n",
       "9499             0             0      0  ...      0      0      0      0   \n",
       "9500             0             0      0  ...      0      0      0      0   \n",
       "\n",
       "      PEP26  PEP27  PEP07  score  final_score  risk  \n",
       "0         0      0      0    2.1         3.44   mid  \n",
       "1         0      0      0    0.1         0.16   low  \n",
       "2         0      0      0    0.1         0.16   low  \n",
       "3         0      0      0    0.8         1.31   low  \n",
       "4         0      0      0    0.1         0.16   low  \n",
       "...     ...    ...    ...    ...          ...   ...  \n",
       "9496      0      0      0    0.7         1.15   low  \n",
       "9497      0      0      0    0.7         1.15   low  \n",
       "9498      1      0      0    0.9         1.48   low  \n",
       "9499      1      0      0    0.9         1.48   low  \n",
       "9500      0      1      0    0.3         0.49   low  \n",
       "\n",
       "[9501 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Desktop/scoring.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(df):\n",
    "    if df['risk'] == 'low':\n",
    "        val = 0\n",
    "    elif df['risk'] == 'middle':\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 2\n",
    "    return val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "9496    0\n",
       "9497    0\n",
       "9498    0\n",
       "9499    0\n",
       "9500    0\n",
       "Name: class, Length: 9501, dtype: int64"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class']=df.apply(f, axis=1)\n",
    "df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_PEP</th>\n",
       "      <th>PEP01</th>\n",
       "      <th>PEP02</th>\n",
       "      <th>PEP03_avto</th>\n",
       "      <th>PEP03_home</th>\n",
       "      <th>PEP03_land</th>\n",
       "      <th>PEP04_adress</th>\n",
       "      <th>PEP04_region</th>\n",
       "      <th>PEP05</th>\n",
       "      <th>...</th>\n",
       "      <th>PEP21</th>\n",
       "      <th>PEP22</th>\n",
       "      <th>PEP23</th>\n",
       "      <th>PEP24</th>\n",
       "      <th>PEP25</th>\n",
       "      <th>PEP26</th>\n",
       "      <th>PEP27</th>\n",
       "      <th>PEP07</th>\n",
       "      <th>score</th>\n",
       "      <th>final_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111759</td>\n",
       "      <td>-0.740036</td>\n",
       "      <td>-0.260503</td>\n",
       "      <td>-0.208987</td>\n",
       "      <td>-0.201356</td>\n",
       "      <td>-0.072728</td>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.065012</td>\n",
       "      <td>0.042297</td>\n",
       "      <td>...</td>\n",
       "      <td>0.150277</td>\n",
       "      <td>0.060156</td>\n",
       "      <td>0.039087</td>\n",
       "      <td>0.070459</td>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.009518</td>\n",
       "      <td>-0.011210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093155</td>\n",
       "      <td>0.093352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_PEP</th>\n",
       "      <td>0.111759</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.196680</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>-0.016534</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>0.038010</td>\n",
       "      <td>-0.041382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>0.011898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP01</th>\n",
       "      <td>-0.740036</td>\n",
       "      <td>-0.196680</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048068</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>-0.112912</td>\n",
       "      <td>-0.117054</td>\n",
       "      <td>-0.082411</td>\n",
       "      <td>-0.063797</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056948</td>\n",
       "      <td>-0.066352</td>\n",
       "      <td>-0.020996</td>\n",
       "      <td>-0.027838</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.104823</td>\n",
       "      <td>-0.105056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP02</th>\n",
       "      <td>-0.260503</td>\n",
       "      <td>0.020529</td>\n",
       "      <td>-0.048068</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>-0.072234</td>\n",
       "      <td>-0.023902</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>0.380017</td>\n",
       "      <td>0.088071</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.071245</td>\n",
       "      <td>0.037194</td>\n",
       "      <td>0.056029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.409180</td>\n",
       "      <td>0.409192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP03_avto</th>\n",
       "      <td>-0.208987</td>\n",
       "      <td>0.078979</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>0.017295</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>-0.039397</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025149</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>-0.011847</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.107425</td>\n",
       "      <td>0.107708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP03_home</th>\n",
       "      <td>-0.201356</td>\n",
       "      <td>0.021350</td>\n",
       "      <td>-0.112912</td>\n",
       "      <td>-0.054148</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.128677</td>\n",
       "      <td>-0.094751</td>\n",
       "      <td>-0.065386</td>\n",
       "      <td>-0.046357</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.081116</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.031113</td>\n",
       "      <td>-0.010740</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.093943</td>\n",
       "      <td>-0.093983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP03_land</th>\n",
       "      <td>-0.072728</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>-0.117054</td>\n",
       "      <td>-0.072234</td>\n",
       "      <td>0.030894</td>\n",
       "      <td>0.128677</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085484</td>\n",
       "      <td>-0.077298</td>\n",
       "      <td>-0.035148</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067838</td>\n",
       "      <td>-0.109299</td>\n",
       "      <td>-0.047603</td>\n",
       "      <td>-0.049165</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.143063</td>\n",
       "      <td>-0.143168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP04_adress</th>\n",
       "      <td>0.076438</td>\n",
       "      <td>0.051250</td>\n",
       "      <td>-0.082411</td>\n",
       "      <td>-0.023902</td>\n",
       "      <td>-0.031552</td>\n",
       "      <td>-0.094751</td>\n",
       "      <td>-0.085484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.657163</td>\n",
       "      <td>-0.036456</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032526</td>\n",
       "      <td>-0.031604</td>\n",
       "      <td>-0.027703</td>\n",
       "      <td>-0.027948</td>\n",
       "      <td>-0.017296</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>-0.012031</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.130224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP04_region</th>\n",
       "      <td>0.065012</td>\n",
       "      <td>0.039181</td>\n",
       "      <td>-0.063797</td>\n",
       "      <td>-0.018606</td>\n",
       "      <td>-0.039397</td>\n",
       "      <td>-0.065386</td>\n",
       "      <td>-0.077298</td>\n",
       "      <td>0.657163</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.023918</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>-0.023482</td>\n",
       "      <td>-0.015676</td>\n",
       "      <td>-0.021261</td>\n",
       "      <td>-0.002589</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098626</td>\n",
       "      <td>0.098618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP05</th>\n",
       "      <td>0.042297</td>\n",
       "      <td>0.007906</td>\n",
       "      <td>-0.021685</td>\n",
       "      <td>-0.034726</td>\n",
       "      <td>-0.024139</td>\n",
       "      <td>-0.046357</td>\n",
       "      <td>-0.035148</td>\n",
       "      <td>-0.036456</td>\n",
       "      <td>-0.020716</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115892</td>\n",
       "      <td>-0.078299</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>-0.031498</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>-0.011768</td>\n",
       "      <td>-0.002751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040749</td>\n",
       "      <td>0.041081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP09</th>\n",
       "      <td>0.001118</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.008577</td>\n",
       "      <td>-0.006934</td>\n",
       "      <td>-0.007391</td>\n",
       "      <td>-0.012395</td>\n",
       "      <td>-0.013686</td>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.004842</td>\n",
       "      <td>-0.004798</td>\n",
       "      <td>...</td>\n",
       "      <td>0.042954</td>\n",
       "      <td>-0.010151</td>\n",
       "      <td>0.040895</td>\n",
       "      <td>-0.006203</td>\n",
       "      <td>-0.003152</td>\n",
       "      <td>-0.001291</td>\n",
       "      <td>-0.001313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.018471</td>\n",
       "      <td>0.018469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP10</th>\n",
       "      <td>0.051545</td>\n",
       "      <td>0.034149</td>\n",
       "      <td>-0.051930</td>\n",
       "      <td>0.010198</td>\n",
       "      <td>-0.008398</td>\n",
       "      <td>-0.029914</td>\n",
       "      <td>-0.050512</td>\n",
       "      <td>-0.013428</td>\n",
       "      <td>-0.018199</td>\n",
       "      <td>-0.029303</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020015</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>-0.002686</td>\n",
       "      <td>-0.001404</td>\n",
       "      <td>0.026182</td>\n",
       "      <td>0.005762</td>\n",
       "      <td>0.005410</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004073</td>\n",
       "      <td>0.004184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP11</th>\n",
       "      <td>0.005637</td>\n",
       "      <td>-0.019061</td>\n",
       "      <td>-0.007489</td>\n",
       "      <td>0.029946</td>\n",
       "      <td>0.007593</td>\n",
       "      <td>-0.006376</td>\n",
       "      <td>-0.002661</td>\n",
       "      <td>-0.002103</td>\n",
       "      <td>0.006284</td>\n",
       "      <td>0.006473</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>0.014410</td>\n",
       "      <td>0.006419</td>\n",
       "      <td>0.035205</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>-0.002083</td>\n",
       "      <td>0.147670</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.061085</td>\n",
       "      <td>0.061092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP13</th>\n",
       "      <td>0.006873</td>\n",
       "      <td>-0.010770</td>\n",
       "      <td>-0.008658</td>\n",
       "      <td>0.033748</td>\n",
       "      <td>-0.008855</td>\n",
       "      <td>-0.021171</td>\n",
       "      <td>-0.025712</td>\n",
       "      <td>-0.004948</td>\n",
       "      <td>-0.004293</td>\n",
       "      <td>0.023297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025327</td>\n",
       "      <td>-0.004626</td>\n",
       "      <td>0.463840</td>\n",
       "      <td>0.017085</td>\n",
       "      <td>0.010950</td>\n",
       "      <td>-0.005473</td>\n",
       "      <td>0.051914</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.128384</td>\n",
       "      <td>0.128367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP15</th>\n",
       "      <td>0.084451</td>\n",
       "      <td>0.012535</td>\n",
       "      <td>-0.056395</td>\n",
       "      <td>-0.030504</td>\n",
       "      <td>-0.031126</td>\n",
       "      <td>-0.042868</td>\n",
       "      <td>-0.060730</td>\n",
       "      <td>-0.050395</td>\n",
       "      <td>-0.029427</td>\n",
       "      <td>0.017646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022341</td>\n",
       "      <td>-0.025345</td>\n",
       "      <td>0.019960</td>\n",
       "      <td>-0.008060</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>-0.002720</td>\n",
       "      <td>-0.003068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.169085</td>\n",
       "      <td>0.169103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP16</th>\n",
       "      <td>0.024223</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>-0.019147</td>\n",
       "      <td>-0.010288</td>\n",
       "      <td>-0.000359</td>\n",
       "      <td>-0.018390</td>\n",
       "      <td>0.000800</td>\n",
       "      <td>-0.010932</td>\n",
       "      <td>-0.007184</td>\n",
       "      <td>-0.007119</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010253</td>\n",
       "      <td>0.001670</td>\n",
       "      <td>-0.007138</td>\n",
       "      <td>0.003083</td>\n",
       "      <td>-0.004677</td>\n",
       "      <td>-0.001916</td>\n",
       "      <td>-0.001948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026399</td>\n",
       "      <td>0.026394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP17</th>\n",
       "      <td>0.049395</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>-0.032037</td>\n",
       "      <td>-0.022798</td>\n",
       "      <td>-0.011640</td>\n",
       "      <td>-0.017131</td>\n",
       "      <td>-0.003272</td>\n",
       "      <td>-0.024062</td>\n",
       "      <td>-0.016195</td>\n",
       "      <td>-0.012116</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019917</td>\n",
       "      <td>-0.018732</td>\n",
       "      <td>-0.012240</td>\n",
       "      <td>-0.018963</td>\n",
       "      <td>-0.014578</td>\n",
       "      <td>-0.008211</td>\n",
       "      <td>-0.008347</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.078718</td>\n",
       "      <td>0.078759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP18</th>\n",
       "      <td>0.068068</td>\n",
       "      <td>-0.097263</td>\n",
       "      <td>-0.043056</td>\n",
       "      <td>0.144662</td>\n",
       "      <td>-0.040851</td>\n",
       "      <td>-0.051085</td>\n",
       "      <td>-0.095730</td>\n",
       "      <td>-0.081104</td>\n",
       "      <td>-0.054329</td>\n",
       "      <td>-0.036150</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006214</td>\n",
       "      <td>0.123531</td>\n",
       "      <td>0.096326</td>\n",
       "      <td>0.113225</td>\n",
       "      <td>0.050578</td>\n",
       "      <td>0.015488</td>\n",
       "      <td>0.089073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.362504</td>\n",
       "      <td>0.362797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP19</th>\n",
       "      <td>-0.035588</td>\n",
       "      <td>0.024499</td>\n",
       "      <td>0.004792</td>\n",
       "      <td>0.053708</td>\n",
       "      <td>0.096890</td>\n",
       "      <td>-0.004173</td>\n",
       "      <td>0.011235</td>\n",
       "      <td>-0.012431</td>\n",
       "      <td>-0.015620</td>\n",
       "      <td>-0.015321</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008740</td>\n",
       "      <td>0.032205</td>\n",
       "      <td>0.030055</td>\n",
       "      <td>0.091630</td>\n",
       "      <td>0.058425</td>\n",
       "      <td>-0.006577</td>\n",
       "      <td>0.025332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.185018</td>\n",
       "      <td>0.184954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP20</th>\n",
       "      <td>0.124195</td>\n",
       "      <td>-0.059690</td>\n",
       "      <td>-0.057522</td>\n",
       "      <td>0.244158</td>\n",
       "      <td>-0.015483</td>\n",
       "      <td>-0.081384</td>\n",
       "      <td>-0.131824</td>\n",
       "      <td>-0.085532</td>\n",
       "      <td>-0.048107</td>\n",
       "      <td>-0.063394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147258</td>\n",
       "      <td>0.352794</td>\n",
       "      <td>0.033084</td>\n",
       "      <td>0.136907</td>\n",
       "      <td>0.065205</td>\n",
       "      <td>0.054311</td>\n",
       "      <td>0.065167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658448</td>\n",
       "      <td>0.658359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP21</th>\n",
       "      <td>0.150277</td>\n",
       "      <td>0.021015</td>\n",
       "      <td>-0.056948</td>\n",
       "      <td>-0.016663</td>\n",
       "      <td>-0.025149</td>\n",
       "      <td>-0.050539</td>\n",
       "      <td>-0.067838</td>\n",
       "      <td>-0.032526</td>\n",
       "      <td>-0.023918</td>\n",
       "      <td>0.115892</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>-0.040356</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.380304</td>\n",
       "      <td>0.380212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP22</th>\n",
       "      <td>0.060156</td>\n",
       "      <td>0.013460</td>\n",
       "      <td>-0.066352</td>\n",
       "      <td>0.380017</td>\n",
       "      <td>-0.007950</td>\n",
       "      <td>-0.081116</td>\n",
       "      <td>-0.109299</td>\n",
       "      <td>-0.031604</td>\n",
       "      <td>-0.011667</td>\n",
       "      <td>-0.078299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023392</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>0.111922</td>\n",
       "      <td>0.057376</td>\n",
       "      <td>0.041022</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.578301</td>\n",
       "      <td>0.578182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP23</th>\n",
       "      <td>0.039087</td>\n",
       "      <td>-0.016534</td>\n",
       "      <td>-0.020996</td>\n",
       "      <td>0.088071</td>\n",
       "      <td>-0.011847</td>\n",
       "      <td>-0.040545</td>\n",
       "      <td>-0.047603</td>\n",
       "      <td>-0.027703</td>\n",
       "      <td>-0.023482</td>\n",
       "      <td>0.008486</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.040356</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>-0.002457</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.217646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP24</th>\n",
       "      <td>0.070459</td>\n",
       "      <td>0.048750</td>\n",
       "      <td>-0.027838</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.013156</td>\n",
       "      <td>-0.031113</td>\n",
       "      <td>-0.049165</td>\n",
       "      <td>-0.027948</td>\n",
       "      <td>-0.015676</td>\n",
       "      <td>-0.031498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035110</td>\n",
       "      <td>0.111922</td>\n",
       "      <td>0.070240</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.229343</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>0.079777</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.457809</td>\n",
       "      <td>0.457715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP25</th>\n",
       "      <td>0.025407</td>\n",
       "      <td>0.011872</td>\n",
       "      <td>-0.018801</td>\n",
       "      <td>0.071245</td>\n",
       "      <td>0.011924</td>\n",
       "      <td>-0.010740</td>\n",
       "      <td>-0.002096</td>\n",
       "      <td>-0.017296</td>\n",
       "      <td>-0.021261</td>\n",
       "      <td>-0.009245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001793</td>\n",
       "      <td>0.057376</td>\n",
       "      <td>0.041164</td>\n",
       "      <td>0.229343</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>0.246303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP26</th>\n",
       "      <td>0.009518</td>\n",
       "      <td>0.038010</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>0.037194</td>\n",
       "      <td>0.020446</td>\n",
       "      <td>0.005491</td>\n",
       "      <td>-0.007982</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>-0.002589</td>\n",
       "      <td>-0.011768</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017024</td>\n",
       "      <td>0.041022</td>\n",
       "      <td>-0.002457</td>\n",
       "      <td>0.036916</td>\n",
       "      <td>0.020095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118744</td>\n",
       "      <td>0.118725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP27</th>\n",
       "      <td>-0.011210</td>\n",
       "      <td>-0.041382</td>\n",
       "      <td>0.019659</td>\n",
       "      <td>0.056029</td>\n",
       "      <td>0.019520</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>-0.012031</td>\n",
       "      <td>-0.002937</td>\n",
       "      <td>-0.002751</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016192</td>\n",
       "      <td>0.039541</td>\n",
       "      <td>0.015577</td>\n",
       "      <td>0.079777</td>\n",
       "      <td>0.046891</td>\n",
       "      <td>-0.003220</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124136</td>\n",
       "      <td>0.124103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PEP07</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>score</th>\n",
       "      <td>0.093155</td>\n",
       "      <td>0.011946</td>\n",
       "      <td>-0.104823</td>\n",
       "      <td>0.409180</td>\n",
       "      <td>0.107425</td>\n",
       "      <td>-0.093943</td>\n",
       "      <td>-0.143063</td>\n",
       "      <td>0.130098</td>\n",
       "      <td>0.098626</td>\n",
       "      <td>0.040749</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380304</td>\n",
       "      <td>0.578301</td>\n",
       "      <td>0.217647</td>\n",
       "      <td>0.457809</td>\n",
       "      <td>0.246344</td>\n",
       "      <td>0.118744</td>\n",
       "      <td>0.124136</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>final_score</th>\n",
       "      <td>0.093352</td>\n",
       "      <td>0.011898</td>\n",
       "      <td>-0.105056</td>\n",
       "      <td>0.409192</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>-0.093983</td>\n",
       "      <td>-0.143168</td>\n",
       "      <td>0.130224</td>\n",
       "      <td>0.098618</td>\n",
       "      <td>0.041081</td>\n",
       "      <td>...</td>\n",
       "      <td>0.380212</td>\n",
       "      <td>0.578182</td>\n",
       "      <td>0.217646</td>\n",
       "      <td>0.457715</td>\n",
       "      <td>0.246303</td>\n",
       "      <td>0.118725</td>\n",
       "      <td>0.124103</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999998</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Unnamed: 0    id_PEP     PEP01     PEP02  PEP03_avto  \\\n",
       "Unnamed: 0      1.000000  0.111759 -0.740036 -0.260503   -0.208987   \n",
       "id_PEP          0.111759  1.000000 -0.196680  0.020529    0.078979   \n",
       "PEP01          -0.740036 -0.196680  1.000000 -0.048068   -0.084906   \n",
       "PEP02          -0.260503  0.020529 -0.048068  1.000000    0.017295   \n",
       "PEP03_avto     -0.208987  0.078979 -0.084906  0.017295    1.000000   \n",
       "PEP03_home     -0.201356  0.021350 -0.112912 -0.054148    0.045972   \n",
       "PEP03_land     -0.072728  0.065554 -0.117054 -0.072234    0.030894   \n",
       "PEP04_adress    0.076438  0.051250 -0.082411 -0.023902   -0.031552   \n",
       "PEP04_region    0.065012  0.039181 -0.063797 -0.018606   -0.039397   \n",
       "PEP05           0.042297  0.007906 -0.021685 -0.034726   -0.024139   \n",
       "PEP09           0.001118  0.004235  0.008577 -0.006934   -0.007391   \n",
       "PEP10           0.051545  0.034149 -0.051930  0.010198   -0.008398   \n",
       "PEP11           0.005637 -0.019061 -0.007489  0.029946    0.007593   \n",
       "PEP13           0.006873 -0.010770 -0.008658  0.033748   -0.008855   \n",
       "PEP15           0.084451  0.012535 -0.056395 -0.030504   -0.031126   \n",
       "PEP16           0.024223 -0.008213 -0.019147 -0.010288   -0.000359   \n",
       "PEP17           0.049395  0.002821 -0.032037 -0.022798   -0.011640   \n",
       "PEP18           0.068068 -0.097263 -0.043056  0.144662   -0.040851   \n",
       "PEP19          -0.035588  0.024499  0.004792  0.053708    0.096890   \n",
       "PEP20           0.124195 -0.059690 -0.057522  0.244158   -0.015483   \n",
       "PEP21           0.150277  0.021015 -0.056948 -0.016663   -0.025149   \n",
       "PEP22           0.060156  0.013460 -0.066352  0.380017   -0.007950   \n",
       "PEP23           0.039087 -0.016534 -0.020996  0.088071   -0.011847   \n",
       "PEP24           0.070459  0.048750 -0.027838  0.096360    0.013156   \n",
       "PEP25           0.025407  0.011872 -0.018801  0.071245    0.011924   \n",
       "PEP26           0.009518  0.038010 -0.014089  0.037194    0.020446   \n",
       "PEP27          -0.011210 -0.041382  0.019659  0.056029    0.019520   \n",
       "PEP07                NaN       NaN       NaN       NaN         NaN   \n",
       "score           0.093155  0.011946 -0.104823  0.409180    0.107425   \n",
       "final_score     0.093352  0.011898 -0.105056  0.409192    0.107708   \n",
       "\n",
       "              PEP03_home  PEP03_land  PEP04_adress  PEP04_region     PEP05  \\\n",
       "Unnamed: 0     -0.201356   -0.072728      0.076438      0.065012  0.042297   \n",
       "id_PEP          0.021350    0.065554      0.051250      0.039181  0.007906   \n",
       "PEP01          -0.112912   -0.117054     -0.082411     -0.063797 -0.021685   \n",
       "PEP02          -0.054148   -0.072234     -0.023902     -0.018606 -0.034726   \n",
       "PEP03_avto      0.045972    0.030894     -0.031552     -0.039397 -0.024139   \n",
       "PEP03_home      1.000000    0.128677     -0.094751     -0.065386 -0.046357   \n",
       "PEP03_land      0.128677    1.000000     -0.085484     -0.077298 -0.035148   \n",
       "PEP04_adress   -0.094751   -0.085484      1.000000      0.657163 -0.036456   \n",
       "PEP04_region   -0.065386   -0.077298      0.657163      1.000000 -0.020716   \n",
       "PEP05          -0.046357   -0.035148     -0.036456     -0.020716  1.000000   \n",
       "PEP09          -0.012395   -0.013686     -0.007368     -0.004842 -0.004798   \n",
       "PEP10          -0.029914   -0.050512     -0.013428     -0.018199 -0.029303   \n",
       "PEP11          -0.006376   -0.002661     -0.002103      0.006284  0.006473   \n",
       "PEP13          -0.021171   -0.025712     -0.004948     -0.004293  0.023297   \n",
       "PEP15          -0.042868   -0.060730     -0.050395     -0.029427  0.017646   \n",
       "PEP16          -0.018390    0.000800     -0.010932     -0.007184 -0.007119   \n",
       "PEP17          -0.017131   -0.003272     -0.024062     -0.016195 -0.012116   \n",
       "PEP18          -0.051085   -0.095730     -0.081104     -0.054329 -0.036150   \n",
       "PEP19          -0.004173    0.011235     -0.012431     -0.015620 -0.015321   \n",
       "PEP20          -0.081384   -0.131824     -0.085532     -0.048107 -0.063394   \n",
       "PEP21          -0.050539   -0.067838     -0.032526     -0.023918  0.115892   \n",
       "PEP22          -0.081116   -0.109299     -0.031604     -0.011667 -0.078299   \n",
       "PEP23          -0.040545   -0.047603     -0.027703     -0.023482  0.008486   \n",
       "PEP24          -0.031113   -0.049165     -0.027948     -0.015676 -0.031498   \n",
       "PEP25          -0.010740   -0.002096     -0.017296     -0.021261 -0.009245   \n",
       "PEP26           0.005491   -0.007982      0.001264     -0.002589 -0.011768   \n",
       "PEP27           0.004405    0.003632     -0.012031     -0.002937 -0.002751   \n",
       "PEP07                NaN         NaN           NaN           NaN       NaN   \n",
       "score          -0.093943   -0.143063      0.130098      0.098626  0.040749   \n",
       "final_score    -0.093983   -0.143168      0.130224      0.098618  0.041081   \n",
       "\n",
       "              ...     PEP21     PEP22     PEP23     PEP24     PEP25     PEP26  \\\n",
       "Unnamed: 0    ...  0.150277  0.060156  0.039087  0.070459  0.025407  0.009518   \n",
       "id_PEP        ...  0.021015  0.013460 -0.016534  0.048750  0.011872  0.038010   \n",
       "PEP01         ... -0.056948 -0.066352 -0.020996 -0.027838 -0.018801 -0.014089   \n",
       "PEP02         ... -0.016663  0.380017  0.088071  0.096360  0.071245  0.037194   \n",
       "PEP03_avto    ... -0.025149 -0.007950 -0.011847  0.013156  0.011924  0.020446   \n",
       "PEP03_home    ... -0.050539 -0.081116 -0.040545 -0.031113 -0.010740  0.005491   \n",
       "PEP03_land    ... -0.067838 -0.109299 -0.047603 -0.049165 -0.002096 -0.007982   \n",
       "PEP04_adress  ... -0.032526 -0.031604 -0.027703 -0.027948 -0.017296  0.001264   \n",
       "PEP04_region  ... -0.023918 -0.011667 -0.023482 -0.015676 -0.021261 -0.002589   \n",
       "PEP05         ...  0.115892 -0.078299  0.008486 -0.031498 -0.009245 -0.011768   \n",
       "PEP09         ...  0.042954 -0.010151  0.040895 -0.006203 -0.003152 -0.001291   \n",
       "PEP10         ... -0.020015  0.000101 -0.002686 -0.001404  0.026182  0.005762   \n",
       "PEP11         ...  0.009478  0.014410  0.006419  0.035205  0.037148 -0.002083   \n",
       "PEP13         ... -0.025327 -0.004626  0.463840  0.017085  0.010950 -0.005473   \n",
       "PEP15         ...  0.022341 -0.025345  0.019960 -0.008060  0.001556 -0.002720   \n",
       "PEP16         ... -0.010253  0.001670 -0.007138  0.003083 -0.004677 -0.001916   \n",
       "PEP17         ... -0.019917 -0.018732 -0.012240 -0.018963 -0.014578 -0.008211   \n",
       "PEP18         ... -0.006214  0.123531  0.096326  0.113225  0.050578  0.015488   \n",
       "PEP19         ... -0.008740  0.032205  0.030055  0.091630  0.058425 -0.006577   \n",
       "PEP20         ...  0.147258  0.352794  0.033084  0.136907  0.065205  0.054311   \n",
       "PEP21         ...  1.000000  0.023392 -0.040356  0.035110 -0.001793  0.017024   \n",
       "PEP22         ...  0.023392  1.000000  0.057420  0.111922  0.057376  0.041022   \n",
       "PEP23         ... -0.040356  0.057420  1.000000  0.070240  0.041164 -0.002457   \n",
       "PEP24         ...  0.035110  0.111922  0.070240  1.000000  0.229343  0.036916   \n",
       "PEP25         ... -0.001793  0.057376  0.041164  0.229343  1.000000  0.020095   \n",
       "PEP26         ...  0.017024  0.041022 -0.002457  0.036916  0.020095  1.000000   \n",
       "PEP27         ...  0.016192  0.039541  0.015577  0.079777  0.046891 -0.003220   \n",
       "PEP07         ...       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "score         ...  0.380304  0.578301  0.217647  0.457809  0.246344  0.118744   \n",
       "final_score   ...  0.380212  0.578182  0.217646  0.457715  0.246303  0.118725   \n",
       "\n",
       "                 PEP27  PEP07     score  final_score  \n",
       "Unnamed: 0   -0.011210    NaN  0.093155     0.093352  \n",
       "id_PEP       -0.041382    NaN  0.011946     0.011898  \n",
       "PEP01         0.019659    NaN -0.104823    -0.105056  \n",
       "PEP02         0.056029    NaN  0.409180     0.409192  \n",
       "PEP03_avto    0.019520    NaN  0.107425     0.107708  \n",
       "PEP03_home    0.004405    NaN -0.093943    -0.093983  \n",
       "PEP03_land    0.003632    NaN -0.143063    -0.143168  \n",
       "PEP04_adress -0.012031    NaN  0.130098     0.130224  \n",
       "PEP04_region -0.002937    NaN  0.098626     0.098618  \n",
       "PEP05        -0.002751    NaN  0.040749     0.041081  \n",
       "PEP09        -0.001313    NaN  0.018471     0.018469  \n",
       "PEP10         0.005410    NaN  0.004073     0.004184  \n",
       "PEP11         0.147670    NaN  0.061085     0.061092  \n",
       "PEP13         0.051914    NaN  0.128384     0.128367  \n",
       "PEP15        -0.003068    NaN  0.169085     0.169103  \n",
       "PEP16        -0.001948    NaN  0.026399     0.026394  \n",
       "PEP17        -0.008347    NaN  0.078718     0.078759  \n",
       "PEP18         0.089073    NaN  0.362504     0.362797  \n",
       "PEP19         0.025332    NaN  0.185018     0.184954  \n",
       "PEP20         0.065167    NaN  0.658448     0.658359  \n",
       "PEP21         0.016192    NaN  0.380304     0.380212  \n",
       "PEP22         0.039541    NaN  0.578301     0.578182  \n",
       "PEP23         0.015577    NaN  0.217647     0.217646  \n",
       "PEP24         0.079777    NaN  0.457809     0.457715  \n",
       "PEP25         0.046891    NaN  0.246344     0.246303  \n",
       "PEP26        -0.003220    NaN  0.118744     0.118725  \n",
       "PEP27         1.000000    NaN  0.124136     0.124103  \n",
       "PEP07              NaN    NaN       NaN          NaN  \n",
       "score         0.124136    NaN  1.000000     0.999998  \n",
       "final_score   0.124103    NaN  0.999998     1.000000  \n",
       "\n",
       "[30 rows x 30 columns]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(columns=['id_PEP','score', 'final_score', 'risk'], axis=1)\n",
    "y=df['score']\n",
    "y1=df['final_score']\n",
    "y2=df['risk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression(fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.85948103e-07, 1.64815777e-01, 6.57267216e-01, 6.58164419e-01,\n",
       "       1.64379720e-01, 1.63887266e-01, 1.14924012e+00, 1.62937373e-01,\n",
       "       6.58491376e-01, 8.20507735e-01, 3.29034523e-01, 3.28470769e-01,\n",
       "       1.14762749e+00, 1.31204623e+00, 1.63990880e+00, 1.31236661e+00,\n",
       "       6.57387519e-01, 9.82873758e-01, 1.31158729e+00, 1.63929422e+00,\n",
       "       1.31145272e+00, 8.19808419e-01, 1.63942254e+00, 1.14767844e+00,\n",
       "       1.47550739e+00, 4.90729184e-01, 0.00000000e+00])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, ytrain, ytest = train_test_split(X, y2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      high\n",
       "1      high\n",
       "2      high\n",
       "3      high\n",
       "4      high\n",
       "       ... \n",
       "976     mid\n",
       "977     mid\n",
       "978     mid\n",
       "979     mid\n",
       "980     mid\n",
       "Name: risk, Length: 981, dtype: object"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#undersampling\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "Xtrain_under, ytrain_under = undersample.fit_resample(Xtrain, ytrain)\n",
    "ytrain_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        low\n",
       "1        low\n",
       "2        low\n",
       "3        mid\n",
       "4        low\n",
       "        ... \n",
       "18517    mid\n",
       "18518    mid\n",
       "18519    mid\n",
       "18520    mid\n",
       "18521    mid\n",
       "Name: risk, Length: 18522, dtype: object"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#oversampling smote\n",
    "sm = SMOTE(random_state=42)\n",
    "Xtrain_sm, ytrain_sm = sm.fit_resample(Xtrain, ytrain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#oversampling randon\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "Xtrain_over, ytrain_over=oversample.fit_resample(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8627946127946128"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier()\n",
    "over = SMOTE(random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "pipeline.fit(Xtrain, ytrain)\n",
    "y_pipe=pipeline.predict(Xtest)\n",
    "pipeline.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    8],\n",
       "       [   2, 1836,  243],\n",
       "       [  24,   49,  213]])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_pipe = confusion_matrix(ytest, y_pipe)\n",
    "mat_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_validate\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_model=model.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9128787878787878"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   7,    0,    2],\n",
       "       [   2, 1953,  126],\n",
       "       [  12,   65,  209]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat = confusion_matrix(ytest, y_model)\n",
    "mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(mat, square=True, annot=True, cbar = False)\n",
    "plt.xlabel(\"predicted value\")\n",
    "plt.ylabel(\"true value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = KNeighborsClassifier(n_neighbors = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8855218855218855"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(Xtrain, ytrain)\n",
    "y_model1=model1.predict(Xtest)\n",
    "model1.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12037037037037036"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_under = KNeighborsClassifier(n_neighbors = 12)\n",
    "model1_under.fit(Xtrain_under, ytrain_under)\n",
    "y_model1_under=model1_under.predict(Xtest)\n",
    "model1_under.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6380471380471381"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1_sm = KNeighborsClassifier(n_neighbors = 12)\n",
    "model1_sm.fit(Xtrain_sm, ytrain_sm)\n",
    "y_model1_sm=model1_under.predict(Xtest)\n",
    "model1_sm.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01568198, 0.00826693, 0.00716591, 0.00734401, 0.00813794]),\n",
       " 'score_time': array([0.33490276, 0.32016301, 0.31668305, 0.30842304, 0.30618405]),\n",
       " 'test_score': array([0.88690163, 0.87578947, 0.88105263, 0.87421053, 0.88578947])}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(model1, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.03884006, 0.00754523, 0.00754285, 0.00735569, 0.0075779 ]),\n",
       " 'score_time': array([0.42933297, 0.38751006, 0.31645608, 0.3181231 , 0.30553484]),\n",
       " 'test_score': array([0.89110994, 0.87736842, 0.88052632, 0.88105263, 0.87631579])}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(model1_under, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.0138042 , 0.00827408, 0.00763488, 0.00923896, 0.00748801]),\n",
       " 'score_time': array([0.416924  , 0.31859612, 0.30995512, 0.31834006, 0.3070693 ]),\n",
       " 'test_score': array([0.87112046, 0.89315789, 0.87526316, 0.88894737, 0.87894737])}"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(model1_sm, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    9,    0],\n",
       "       [   0, 2037,   44],\n",
       "       [   0,  219,   67]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = confusion_matrix(ytest, y_model1)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    9,    0],\n",
       "       [   0, 2037,   44],\n",
       "       [   0,  219,   67]])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat11=confusion_matrix(ytest, y_model1_under)\n",
    "mat1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    9],\n",
       "       [   0,    0, 2081],\n",
       "       [   0,    0,  286]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1_sm=confusion_matrix(ytest, y_model1_sm)\n",
    "mat1_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(mat1, square=True, annot=True, cbar = False)\n",
    "plt.xlabel(\"predicted value\")\n",
    "plt.ylabel(\"true value\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor, plot_tree\n",
    "dtr=DecisionTreeRegressor(max_depth = 12)\n",
    "X1train, X1test, y1train, y1test = train_test_split(X, y1, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=12)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.fit(X1train, y1train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dtr=dtr.predict(X1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02101302, 0.01836491, 0.01547861, 0.01531005, 0.01661181]),\n",
       " 'score_time': array([0.00491166, 0.00230813, 0.00188637, 0.00186706, 0.0018611 ]),\n",
       " 'test_score': array([0.96228508, 0.95338103, 0.95745648, 0.95712074, 0.95916254])}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(dtr, X, y1, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9534731468496402"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.score(X1test, y1test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.984006734006734"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(Xtrain, ytrain)\n",
    "dt_y=dt.predict(Xtest)\n",
    "dt.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7672558922558923"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_under = DecisionTreeClassifier()\n",
    "dt_under.fit(Xtrain_under, ytrain_under)\n",
    "dt_y_under=dt.predict(Xtest)\n",
    "dt_under.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8636363636363636"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_sm = DecisionTreeClassifier()\n",
    "dt_sm.fit(Xtrain_sm, ytrain_sm)\n",
    "dt_y_sm=dt.predict(Xtest)\n",
    "dt_sm.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9823232323232324"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt_over = DecisionTreeClassifier()\n",
    "dt_over.fit(Xtrain_over, ytrain_over)\n",
    "dt_y_over=dt.predict(Xtest)\n",
    "dt_over.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    8],\n",
       "       [   0, 2075,    6],\n",
       "       [   6,   18,  262]])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dt = confusion_matrix(ytest, dt_y_over)\n",
    "mat_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02870393, 0.02335095, 0.01853013, 0.0185113 , 0.01874185]),\n",
       " 'score_time': array([0.00320721, 0.00294089, 0.00291586, 0.00305676, 0.00312304]),\n",
       " 'test_score': array([0.98527091, 0.98157895, 0.98684211, 0.98684211, 0.98      ])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(dt, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.02577329, 0.02177382, 0.01865077, 0.01800704, 0.01664186]),\n",
       " 'score_time': array([0.00418091, 0.00270915, 0.00277114, 0.00274801, 0.0028162 ]),\n",
       " 'test_score': array([0.9879011 , 0.98473684, 0.97947368, 0.98368421, 0.98526316])}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(dt_under, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    8],\n",
       "       [   0, 2075,    6],\n",
       "       [   6,   18,  262]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dt = confusion_matrix(ytest, dt_y)\n",
    "mat_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    8],\n",
       "       [   0, 2075,    6],\n",
       "       [   6,   18,  262]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dt_under=confusion_matrix(ytest,dt_y_under)\n",
    "mat_dt_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    8],\n",
       "       [   0, 2075,    6],\n",
       "       [   6,   18,  262]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_dt_sm=confusion_matrix(ytest,dt_y_sm)\n",
    "mat_dt_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "Adb = AdaBoostClassifier(n_estimators=3, base_estimator=DecisionTreeClassifier(max_depth=1), random_state=1)\n",
    "\n",
    "# train AdaBoost on our data\n",
    "np.random.seed(1111)\n",
    "Adb.fit(Xtrain, ytrain)\n",
    "adb_y=Adb.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9255050505050505"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adb.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156565656565656"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Adb_sm = AdaBoostClassifier(n_estimators=3, base_estimator=DecisionTreeClassifier(max_depth=1), random_state=1)\n",
    "\n",
    "# train AdaBoost on our data\n",
    "np.random.seed(1111)\n",
    "Adb_sm.fit(Xtrain_sm, ytrain_sm)\n",
    "adb_y_sm=Adb.predict(Xtest)\n",
    "Adb_sm.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8156565656565656"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=3, base_estimator=DecisionTreeClassifier(max_depth=1), random_state=1)\n",
    "over = SMOTE(random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model)]\n",
    "pipeline_adb = Pipeline(steps=steps)\n",
    "\n",
    "pipeline_adb.fit(Xtrain, ytrain)\n",
    "y_pipe_adb=pipeline_adb.predict(Xtest)\n",
    "pipeline_adb.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    9],\n",
       "       [   0, 2018,   63],\n",
       "       [   0,  105,  181]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_adb = confusion_matrix(ytest, adb_y)\n",
    "mat_adb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    9],\n",
       "       [   0, 2018,   63],\n",
       "       [   0,  105,  181]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_adb_sm=confusion_matrix(ytest, adb_y_sm)\n",
    "mat_adb_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    0,    1],\n",
       "       [   8, 1759,  314],\n",
       "       [  68,   47,  171]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_adb_pipe=confusion_matrix(ytest, y_pipe_adb)\n",
    "mat_adb_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6372053872053872"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=3, base_estimator=DecisionTreeClassifier(max_depth=10), random_state=42)\n",
    "over = SMOTE(random_state=42)\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model1)]\n",
    "pipeline_adb_1 = Pipeline(steps=steps)\n",
    "\n",
    "pipeline_adb_1.fit(Xtrain, ytrain)\n",
    "y_pipe_adb_1=pipeline_adb.predict(Xtest)\n",
    "pipeline_adb_1.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    0,    1],\n",
       "       [   8, 1759,  314],\n",
       "       [  68,   47,  171]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_adb_pipe1=confusion_matrix(ytest, y_pipe_adb_1)\n",
    "mat_adb_pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.04842067, 0.03181982, 0.0289669 , 0.02981997, 0.03110313]),\n",
       " 'score_time': array([0.00532722, 0.00351501, 0.00350213, 0.00454283, 0.00421381]),\n",
       " 'test_score': array([0.93161494, 0.92315789, 0.92473684, 0.93526316, 0.93      ])}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results=cross_validate(Adb, X, y2, cv=kf, return_train_score=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9865319865319865"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = AdaBoostClassifier(n_estimators=10, base_estimator=DecisionTreeClassifier(max_depth=24), random_state=42)\n",
    "over = RandomOverSampler(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model2)]\n",
    "pipeline_adb_2 = Pipeline(steps=steps)\n",
    "\n",
    "pipeline_adb_2.fit(Xtrain, ytrain)\n",
    "y_pipe_adb_2=pipeline_adb.predict(Xtest)\n",
    "pipeline_adb_2.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    0,    1],\n",
       "       [   8, 1759,  314],\n",
       "       [  68,   47,  171]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_adb_pipe2=confusion_matrix(ytest, y_pipe_adb_2)\n",
    "mat_adb_pipe2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonyashka/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8051346801346801"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "over = SMOTE()\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model)]\n",
    "pipeline_lr = Pipeline(steps=steps)\n",
    "\n",
    "pipeline_lr.fit(Xtrain, ytrain)\n",
    "y_pipe_lr=pipeline_adb.predict(Xtest)\n",
    "pipeline_lr.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tonyashka/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9478114478114478"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "over = RandomOverSampler(sampling_strategy='minority')\n",
    "under = RandomUnderSampler(sampling_strategy='majority')\n",
    "steps = [('o', over), ('u', under), ('model', model)]\n",
    "pipeline_lr1 = Pipeline(steps=steps)\n",
    "\n",
    "pipeline_lr1.fit(Xtrain, ytrain)\n",
    "y_pipe_lr1=pipeline_adb.predict(Xtest)\n",
    "pipeline_lr1.score(Xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    0,    1],\n",
       "       [   8, 1759,  314],\n",
       "       [  68,   47,  171]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_lr_pipe1=confusion_matrix(ytest, y_pipe_lr1)\n",
    "mat_lr_pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,    0,    1],\n",
       "       [   8, 1759,  314],\n",
       "       [  68,   47,  171]])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat_lr_pipe=confusion_matrix(ytest, y_pipe_lr)\n",
    "mat_lr_pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "#idea to use clasters \n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "clustering = AgglomerativeClustering(n_clusters = 3, linkage = 'single').fit(X)\n",
    "X['clusters'] = clustering.labels_\n",
    "X['clusters'] = X['clusters'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2238"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X['clusters']==df['class']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
